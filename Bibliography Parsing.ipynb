{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Notes\n",
    "* Use the citation network to get an idea of what papers you might want to add, especially since that'll give you a good idea of what's already linking the fields\n",
    "* What am I going to DO with this dataset? Specifically problem attributes and strategies.\n",
    "    * Mathematica visuals will be great\n",
    "    * What other kinds of statistical analysis would be useful? \n",
    "* It's not useful unless I can get other people to use it, so how am I going to do that?\n",
    "    * Pester people once I have preliminary results about how I can make this useful to them?\n",
    "    * Good Github repository and readme\n",
    "    * Edit Wikipedia articles?\n",
    "* Citation tools: use a parser (anystyle or freecite) and then query web of science, scopus, or scifinder?\n",
    "* Project defense: approved with a couple hrs of changes, vs like a week or two?\n",
    "\n",
    "#### Code-Related Next Steps\n",
    "* Put it in a github repository\n",
    "* Look at connectivity on Wikipedia between network topics and graph topics\n",
    "\n",
    "#### Notes on Crossref item properties:\n",
    "* 'container-title' is the journal title, which I don't currently care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Not currently being used \n",
    "import csv \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For reading in bib.txt files\n",
    "import re\n",
    "import glob\n",
    "\n",
    "# For getting the spreadsheet\n",
    "import urllib\n",
    "import gspread\n",
    "import requests\n",
    "\n",
    "# For using the .py database classes\n",
    "import importlib\n",
    "import paper\n",
    "import database\n",
    "import subject_assignment as subjects\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from bs4 import BeautifulSoup, Comment, NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parents read from file: 221\n",
      "All parents added from file; no lookup necessary\n",
      "(1 of 221) Bib #1: All children added from file\n",
      "(2 of 221) Bib #10: All children added from file\n",
      "(3 of 221) Bib #100: All children added from file\n",
      "(4 of 221) Bib #101: All children added from file\n",
      "(5 of 221) Bib #102: All children added from file\n",
      "DON'T ADD AN EMPTY PAPER, DUMMY\n",
      "(6 of 221) Bib #103: All children added from file\n",
      "(7 of 221) Bib #104: All children added from file\n",
      "(8 of 221) Bib #105: All children added from file\n",
      "(9 of 221) Bib #106: All children added from file\n",
      "(10 of 221) Bib #107: All children added from file\n",
      "(11 of 221) Bib #108: All children added from file\n",
      "(12 of 221) Bib #109: All children added from file\n",
      "(13 of 221) Bib #11: All children added from file\n",
      "(14 of 221) Bib #110: All children added from file\n",
      "(15 of 221) Bib #111: All children added from file\n",
      "(16 of 221) Bib #112: All children added from file\n",
      "(17 of 221) Bib #113: All children added from file\n",
      "(18 of 221) Bib #114: All children added from file\n",
      "(19 of 221) Bib #115: All children added from file\n",
      "(20 of 221) Bib #116: All children added from file\n",
      "(21 of 221) Bib #117: All children added from file\n",
      "(22 of 221) Bib #118: All children added from file\n",
      "(23 of 221) Bib #119: All children added from file\n",
      "(24 of 221) Bib #12: All children added from file\n",
      "(25 of 221) Bib #120: All children added from file\n",
      "(26 of 221) Bib #121: All children added from file\n",
      "(27 of 221) Bib #122: All children added from file\n",
      "(28 of 221) Bib #123: All children added from file\n",
      "(29 of 221) Bib #124: All children added from file\n",
      "(30 of 221) Bib #125: All children added from file\n",
      "(31 of 221) Bib #126: All children added from file\n",
      "(32 of 221) Bib #127: All children added from file\n",
      "(33 of 221) Bib #128: All children added from file\n",
      "(34 of 221) Bib #129: All children added from file\n",
      "(35 of 221) Bib #13: All children added from file\n",
      "(36 of 221) Bib #130: All children added from file\n",
      "(37 of 221) Bib #131: All children added from file\n",
      "(38 of 221) Bib #132: All children added from file\n",
      "(39 of 221) Bib #133: All children added from file\n",
      "(40 of 221) Bib #134: All children added from file\n",
      "(41 of 221) Bib #135: All children added from file\n",
      "(42 of 221) Bib #136: All children added from file\n",
      "(43 of 221) Bib #137: All children added from file\n",
      "(44 of 221) Bib #138: All children added from file\n",
      "(45 of 221) Bib #139: All children added from file\n",
      "(46 of 221) Bib #14: All children added from file\n",
      "(47 of 221) Bib #140: All children added from file\n",
      "(48 of 221) Bib #141: All children added from file\n",
      "(49 of 221) Bib #142: All children added from file\n",
      "(50 of 221) Bib #143: All children added from file\n",
      "(51 of 221) Bib #144: All children added from file\n",
      "(52 of 221) Bib #145: All children added from file\n",
      "(53 of 221) Bib #146: All children added from file\n",
      "(54 of 221) Bib #147: All children added from file\n",
      "(55 of 221) Bib #148: All children added from file\n",
      "(56 of 221) Bib #149: All children added from file\n",
      "(57 of 221) Bib #15: All children added from file\n",
      "(58 of 221) Bib #150: All children added from file\n",
      "(59 of 221) Bib #151: All children added from file\n",
      "(60 of 221) Bib #152: All children added from file\n",
      "(61 of 221) Bib #153: All children added from file\n",
      "(62 of 221) Bib #154: All children added from file\n",
      "(63 of 221) Bib #155: All children added from file\n",
      "(64 of 221) Bib #156: All children added from file\n",
      "(65 of 221) Bib #157: All children added from file\n",
      "(66 of 221) Bib #158: All children added from file\n",
      "(67 of 221) Bib #159: All children added from file\n",
      "(68 of 221) Bib #16: All children added from file\n",
      "(69 of 221) Bib #160: All children added from file\n",
      "(70 of 221) Bib #161: All children added from file\n",
      "(71 of 221) Bib #162: All children added from file\n",
      "(72 of 221) Bib #163: All children added from file\n",
      "(73 of 221) Bib #164: All children added from file\n",
      "(74 of 221) Bib #165: All children added from file\n",
      "(75 of 221) Bib #166: All children added from file\n",
      "(76 of 221) Bib #167: All children added from file\n",
      "(77 of 221) Bib #168: All children added from file\n",
      "(78 of 221) Bib #169: All children added from file\n",
      "(79 of 221) Bib #17: All children added from file\n",
      "(80 of 221) Bib #170: All children added from file\n",
      "(81 of 221) Bib #171: All children added from file\n",
      "(82 of 221) Bib #172: All children added from file\n",
      "(83 of 221) Bib #173: All children added from file\n",
      "(84 of 221) Bib #174: All children added from file\n",
      "(85 of 221) Bib #175: All children added from file\n",
      "(86 of 221) Bib #176: All children added from file\n",
      "(87 of 221) Bib #177: All children added from file\n",
      "(88 of 221) Bib #178: All children added from file\n",
      "(89 of 221) Bib #179: All children added from file\n",
      "(90 of 221) Bib #18: All children added from file\n",
      "(91 of 221) Bib #180: All children added from file\n",
      "(92 of 221) Bib #181: All children added from file\n",
      "(93 of 221) Bib #182: All children added from file\n",
      "(94 of 221) Bib #183: All children added from file\n",
      "(95 of 221) Bib #184: All children added from file\n",
      "(96 of 221) Bib #185: All children added from file\n",
      "(97 of 221) Bib #186: All children added from file\n",
      "(98 of 221) Bib #187: All children added from file\n",
      "(99 of 221) Bib #188: All children added from file\n",
      "(100 of 221) Bib #189: All children added from file\n",
      "(101 of 221) Bib #19: All children added from file\n",
      "(102 of 221) Bib #190: All children added from file\n",
      "(103 of 221) Bib #191: All children added from file\n",
      "(104 of 221) Bib #192: All children added from file\n",
      "(105 of 221) Bib #193: All children added from file\n",
      "DON'T ADD AN EMPTY PAPER, DUMMY\n",
      "(106 of 221) Bib #194: All children added from file\n",
      "(107 of 221) Bib #195: All children added from file\n",
      "(108 of 221) Bib #196: All children added from file\n",
      "(109 of 221) Bib #197: All children added from file\n",
      "(110 of 221) Bib #198: All children added from file\n",
      "(111 of 221) Bib #199: All children added from file\n",
      "(112 of 221) Bib #2: All children added from file\n",
      "(113 of 221) Bib #20: All children added from file\n",
      "(114 of 221) Bib #200: All children added from file\n",
      "(115 of 221) Bib #201: All children added from file\n",
      "(116 of 221) Bib #202: All children added from file\n",
      "(117 of 221) Bib #203: All children added from file\n",
      "(118 of 221) Bib #204: All children added from file\n",
      "(119 of 221) Bib #205: All children added from file\n",
      "(120 of 221) Bib #206: All children added from file\n",
      "(121 of 221) Bib #207: All children added from file\n",
      "(122 of 221) Bib #208: All children added from file\n",
      "(123 of 221) Bib #209: All children added from file\n",
      "(124 of 221) Bib #21: All children added from file\n",
      "(125 of 221) Bib #210: All children added from file\n",
      "(126 of 221) Bib #211: All children added from file\n",
      "(127 of 221) Bib #212: All children added from file\n",
      "(128 of 221) Bib #213: All children added from file\n",
      "(129 of 221) Bib #214: All children added from file\n",
      "(130 of 221) Bib #215: All children added from file\n",
      "(131 of 221) Bib #216: All children added from file\n",
      "(132 of 221) Bib #217: All children added from file\n",
      "(133 of 221) Bib #218: All children added from file\n",
      "(134 of 221) Bib #219: All children added from file\n",
      "(135 of 221) Bib #22: All children added from file\n",
      "(136 of 221) Bib #220: All children added from file\n",
      "(137 of 221) Bib #221: All children added from file\n",
      "(138 of 221) Bib #23: All children added from file\n",
      "(139 of 221) Bib #24: All children added from file\n",
      "(140 of 221) Bib #25: All children added from file\n",
      "(141 of 221) Bib #26: All children added from file\n",
      "(142 of 221) Bib #27: All children added from file\n",
      "(143 of 221) Bib #28: All children added from file\n",
      "(144 of 221) Bib #29: All children added from file\n",
      "(145 of 221) Bib #3: All children added from file\n",
      "(146 of 221) Bib #30: All children added from file\n",
      "(147 of 221) Bib #31: All children added from file\n",
      "(148 of 221) Bib #32: All children added from file\n",
      "(149 of 221) Bib #33: All children added from file\n",
      "(150 of 221) Bib #34: All children added from file\n",
      "(151 of 221) Bib #35: All children added from file\n",
      "(152 of 221) Bib #36: All children added from file\n",
      "(153 of 221) Bib #37: All children added from file\n",
      "(154 of 221) Bib #38: All children added from file\n",
      "(155 of 221) Bib #39: All children added from file\n",
      "(156 of 221) Bib #4: All children added from file\n",
      "(157 of 221) Bib #40: All children added from file\n",
      "(158 of 221) Bib #41: All children added from file\n",
      "(159 of 221) Bib #42: All children added from file\n",
      "(160 of 221) Bib #43: All children added from file\n",
      "(161 of 221) Bib #44: All children added from file\n",
      "(162 of 221) Bib #45: All children added from file\n",
      "(163 of 221) Bib #46: All children added from file\n",
      "(164 of 221) Bib #47: All children added from file\n",
      "(165 of 221) Bib #48: All children added from file\n",
      "(166 of 221) Bib #49: All children added from file\n",
      "(167 of 221) Bib #5: All children added from file\n",
      "(168 of 221) Bib #50: All children added from file\n",
      "(169 of 221) Bib #51: All children added from file\n",
      "(170 of 221) Bib #52: All children added from file\n",
      "(171 of 221) Bib #53: All children added from file\n",
      "(172 of 221) Bib #54: All children added from file\n",
      "(173 of 221) Bib #55: All children added from file\n",
      "(174 of 221) Bib #56: All children added from file\n",
      "(175 of 221) Bib #57: All children added from file\n",
      "(176 of 221) Bib #58: All children added from file\n",
      "(177 of 221) Bib #59: All children added from file\n",
      "(178 of 221) Bib #6: All children added from file\n",
      "(179 of 221) Bib #60: All children added from file\n",
      "(180 of 221) Bib #61: All children added from file\n",
      "(181 of 221) Bib #62: All children added from file\n",
      "(182 of 221) Bib #63: All children added from file\n",
      "(183 of 221) Bib #64: All children added from file\n",
      "(184 of 221) Bib #65: All children added from file\n",
      "(185 of 221) Bib #66: All children added from file\n",
      "(186 of 221) Bib #67: All children added from file\n",
      "(187 of 221) Bib #68: All children added from file\n",
      "(188 of 221) Bib #69: All children added from file\n",
      "(189 of 221) Bib #7: All children added from file\n",
      "(190 of 221) Bib #70: All children added from file\n",
      "(191 of 221) Bib #71: All children added from file\n",
      "(192 of 221) Bib #72: All children added from file\n",
      "(193 of 221) Bib #73: All children added from file\n",
      "(194 of 221) Bib #74: All children added from file\n",
      "(195 of 221) Bib #75: All children added from file\n",
      "(196 of 221) Bib #76: All children added from file\n",
      "(197 of 221) Bib #77: All children added from file\n",
      "(198 of 221) Bib #78: All children added from file\n",
      "(199 of 221) Bib #79: All children added from file\n",
      "(200 of 221) Bib #8: All children added from file\n",
      "(201 of 221) Bib #80: All children added from file\n",
      "(202 of 221) Bib #81: All children added from file\n",
      "(203 of 221) Bib #82: All children added from file\n",
      "(204 of 221) Bib #83: All children added from file\n",
      "(205 of 221) Bib #84: All children added from file\n",
      "(206 of 221) Bib #85: All children added from file\n",
      "(207 of 221) Bib #86: All children added from file\n",
      "(208 of 221) Bib #87: All children added from file\n",
      "(209 of 221) Bib #88: All children added from file\n",
      "(210 of 221) Bib #89: All children added from file\n",
      "(211 of 221) Bib #9: All children added from file\n",
      "(212 of 221) Bib #90: All children added from file\n",
      "(213 of 221) Bib #91: All children added from file\n",
      "(214 of 221) Bib #92: All children added from file\n",
      "(215 of 221) Bib #93: All children added from file\n",
      "(216 of 221) Bib #94: All children added from file\n",
      "(217 of 221) Bib #95: All children added from file\n",
      "(218 of 221) Bib #96: All children added from file\n",
      "(219 of 221) Bib #97: All children added from file\n",
      "(220 of 221) Bib #98: All children added from file\n",
      "(221 of 221) Bib #99: All children added from file\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(database)\n",
    "importlib.reload(paper)\n",
    "\n",
    "db = database.Database()\n",
    "db.initialize_parents(\"parents.txt\")\n",
    "#db.sync_parents()\n",
    "db.rewrite_parents(\"parents.txt\")\n",
    "db.initialize_children()\n",
    "#db.write_bads(<filename>)\n",
    "#db.update_bads(<filename>)\n",
    "db.rewrite_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.update_bads(\"fixed_lastcallfornewguys.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of all reference lists: 7640\n",
      "Total number of papers: 5791\n",
      "\n",
      "\t 0 unchecked and unverified\n",
      "\n",
      "\t 3823 papers unchecked\n",
      "\t 1968 papers manually checked\n",
      "\t 0 papers to get rid of\n",
      "\t 5791 total\n",
      "\n",
      "\t 5682 papers known to be correct\n",
      "\t 109 not quite right, but close enough\n",
      "\t 0 entries just wrong\n",
      "\t 5791 total\n"
     ]
    }
   ],
   "source": [
    "db.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.to_csv(\"final_database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers with a container-title: 5635\n",
      "Number of papers without a container-title: 156\n",
      "Number of unique container titles: 2284\n",
      "\n",
      "Total number of journals: 2284\n",
      "Number of journals assigned a topic: 1502\n",
      "Number of journals with no topic assigned: 782\n",
      "\tNumber of 'Computer Science': 984\n",
      "\tNumber of 'Biology': 296\n",
      "\tNumber of 'Mathematics': 419\n",
      "\n",
      "Total number of papers: 5791\n",
      "Number of papers assigned a topic: 4089\n",
      "Number of papers with no topic assigned: 1702\n",
      "\tNumber of 'Computer Science': 2664\n",
      "\tNumber of 'Biology': 1056\n",
      "\tNumber of 'Mathematics': 901\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(subjects)\n",
    "\n",
    "subjects.clear_subjects(db)\n",
    "journals = subjects.initialize_journals(db, verbose=True)\n",
    "print()\n",
    "topics = subjects.get_wordlists()\n",
    "\n",
    "journals, journals_by_topic = subjects.tag_journals(db, journals, topics, \n",
    "                                                    verbose=True)\n",
    "print()\n",
    "papers_by_topic = subjects.tag_papers(db, journals, topics, verbose=True)\n",
    "with open('journal_titles.txt','w',errors='backslashreplace') as f:\n",
    "    for journal in journals:\n",
    "        is_1 = subjects.check_words(journal, topics['Biology'])\n",
    "        is_2 = subjects.check_words(journal, topics['Mathematics'])\n",
    "        is_3 = subjects.check_words(journal, topics['Computer Science'])\n",
    "        if is_1 == False and is_2 == False and is_3 == False:\n",
    "            f.write(str(journal)+'\\n')\n",
    "            \n",
    "\n",
    "with open('all_journal_titles.txt','w',errors='backslashreplace') as f:\n",
    "    for journal in journals:\n",
    "        f.write(str(journal)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_with_word = dict()\n",
    "for topic in topics:\n",
    "    topic_word = dict()\n",
    "    for word in topics[topic]:\n",
    "        is_word = set()\n",
    "        for p_hash, p in db.all_papers.items():\n",
    "            p_hasword = False\n",
    "            if p.container_title:\n",
    "                for thing in p.container_title:\n",
    "                    if subjects.check_words(thing, [word]):\n",
    "                        p_hasword = True\n",
    "            if p_hasword:\n",
    "                is_word.add(p_hash)\n",
    "        topic_word[word] = len(is_word.intersection(papers_by_topic[topic]))\n",
    "    num_with_word[topic] = topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Science:\n",
      "\t 16 Machine Vision\n",
      "\t 72 Data Mining\n",
      "\t 44 Graphics\n",
      "\t 30 World Wide Web\n",
      "\t 19 Internet\n",
      "\t 400 Computer Science\n",
      "\t 15 Robotic\n",
      "\t 8 Electrical Engineering\n",
      "\t 91 SIAM\n",
      "\t 22 Image Analysis\n",
      "\t 17 Computational Intelligence\n",
      "\t 6 Computational linguistics\n",
      "\t 3 ITiCSE\n",
      "\t 59 Image Processing\n",
      "\t 12 Language Processing\n",
      "\t 21 learning\n",
      "\t 340 ACM\n",
      "\t 837 Computer\n",
      "\t 74 Artificial Intelligence\n",
      "\t 444 Pattern Recognition\n",
      "\t 52 Machine Learning\n",
      "\t 22 Computer Graphics\n",
      "\t 7 Scientific Computing\n",
      "\t 38 Computational Linguistics\n",
      "\t 329 Computer Vision\n",
      "\t 1 Artificial intelligence\n",
      "\t 4 Malware\n",
      "\t 82 Learning\n",
      "\t 82 Signal Processing\n",
      "\t 51 Software\n",
      "\t 254 Data\n",
      "\t 19 Machine learning\n",
      "\t 1 CIVR\n",
      "\t 14 Intelligent Systems\n",
      "\t 20 Document Analysis\n",
      "\t 59 Neural Networks\n",
      "\t 57 Algorithm\n",
      "\t 1 ITICSE\n",
      "\t 932 IEEE\n",
      "Biology:\n",
      "\t 9 Drug\n",
      "\t 6 Microbiology\n",
      "\t 8 PLANT\n",
      "\t 11 biomedica\n",
      "\t 4 DNA\n",
      "\t 4 Biosystems\n",
      "\t 235 Biology\n",
      "\t 15 Brain\n",
      "\t 11 biology\n",
      "\t 17 Genomic\n",
      "\t 13 Cancer\n",
      "\t 25 Biomedic\n",
      "\t 43 Protein\n",
      "\t 15 Psychology\n",
      "\t 9 Biochem\n",
      "\t 1 Neurobiological\n",
      "\t 1 Pathogens\n",
      "\t 15 Medicinal\n",
      "\t 1 Diseases\n",
      "\t 6 Pathology\n",
      "\t 1 Virus\n",
      "\t 17 Virology\n",
      "\t 18 Biotechnology\n",
      "\t 10 Proteom\n",
      "\t 1 Bioengineering\n",
      "\t 112 Molecular\n",
      "\t 280 Bioinformatics\n",
      "\t 33 Psych\n",
      "\t 3 Pharma\n",
      "\t 1 Endocrinology\n",
      "\t 10 Plant\n",
      "\t 1 Epidemiology\n",
      "\t 31 Cell\n",
      "\t 10 Biocomputing\n",
      "\t 28 Biological\n",
      "\t 38 Genome\n",
      "\t 52 Genetics\n",
      "\t 111 Neuro\n",
      "\t 1 Cardiology\n",
      "\t 20 Medicine\n",
      "\t 15 Biomedical\n",
      "\t 1 Metabolic\n",
      "\t 43 Medical\n",
      "Mathematics:\n",
      "\t 2 Markov\n",
      "\t 1 Functional Analysis\n",
      "\t 91 SIAM\n",
      "\t 4 Wavelet\n",
      "\t 20 Optimization\n",
      "\t 15 Graphs\n",
      "\t 63 Combinatori\n",
      "\t 112 Statistic\n",
      "\t 2 Topology\n",
      "\t 54 Statistics\n",
      "\t 2 geometry\n",
      "\t 26 Algebra\n",
      "\t 1 Riemann Surfaces\n",
      "\t 2 Multivariate\n",
      "\t 2 Permutation Groups\n",
      "\t 1 Fractal\n",
      "\t 15 Geometr\n",
      "\t 13 Probability\n",
      "\t 10 Kernel\n",
      "\t 1 Fixed Point\n",
      "\t 2 mathemati\n",
      "\t 47 Graph \n",
      "\t 280 Mathemati\n",
      "\t 1 Linear Regression\n",
      "\t 57 Algorithm\n",
      "\t 4 Chaos\n",
      "\t 152 Network\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic + \":\")\n",
    "    for word in topics[topic]:\n",
    "        print(\"\\t\", num_with_word[topic][word], word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers with a container-title: 5635\n",
      "Number of papers without a container-title: 156\n",
      "Number of unique container titles: 2284\n",
      "\n",
      "39\n",
      "43\n",
      "27\n",
      "Total number of journals: 2284\n",
      "Number of journals assigned a topic: 1497\n",
      "Number of journals with no topic assigned: 787\n",
      "\tNumber of 'Computer Science': 984\n",
      "\tNumber of 'Biology': 296\n",
      "\tNumber of 'Mathematics': 393\n",
      "\n",
      "Total number of papers: 5791\n",
      "Number of papers assigned a topic: 4085\n",
      "Number of papers with no topic assigned: 1706\n",
      "\tNumber of 'Computer Science': 2664\n",
      "\tNumber of 'Biology': 1056\n",
      "\tNumber of 'Mathematics': 823\n",
      "\n",
      "143\n",
      "Computer Science 143\n",
      "Biology 5\n",
      "Mathematics 143\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(subjects)\n",
    "\n",
    "subjects.clear_subjects(db)\n",
    "journals = subjects.initialize_journals(db, verbose=True)\n",
    "print()\n",
    "topics = subjects.get_wordlists()\n",
    "for topic in topics:\n",
    "    print(len(topics[topic]))\n",
    "\n",
    "journals, journals_by_topic = subjects.tag_journals(db, journals, topics, \n",
    "                                                    verbose=True)\n",
    "\n",
    "is_big3 = set()\n",
    "big3 = {'Algorithm','SIAM'}\n",
    "for p_hash, p in db.all_papers.items():\n",
    "    p_inbig3 = False\n",
    "    if p.container_title:\n",
    "        for thing in p.container_title:\n",
    "            if subjects.check_words(thing, big3):\n",
    "                p_inbig3 = True\n",
    "    if p_inbig3:\n",
    "        is_big3.add(p_hash)\n",
    "        \n",
    "print()\n",
    "papers_by_topic = subjects.tag_papers(db, journals, topics, verbose=True)\n",
    "print()\n",
    "print(len(is_big3))\n",
    "for topic, topicpapers in papers_by_topic.items():\n",
    "    print(topic, len(is_big3.intersection(topicpapers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers with 0 topics: 1706\n",
      "Number of papers with 1 topics: 3633\n",
      "Number of papers with 2 topics: 446\n",
      "Number of papers with 3 topics: 6\n",
      "frozenset({'Mathematics', 'Computer Science'}) 319\n",
      "frozenset({'Biology', 'Computer Science'}) 107\n",
      "frozenset({'Mathematics', 'Biology'}) 20\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(subjects)\n",
    "\n",
    "subjects.check_intersections(db, topics, papers_by_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: ('Collective dynamics of Â‘small-worldÂ’ networks', 1998.0)\n",
      "FAILURE: ('Efficient Graph Matching Algorithms', 1995.0)\n",
      "FAILED: ('NETAL: a new graph-based method for global alignment of proteinÂ–protein interaction networks', 2013.0)\n",
      "FAILURE: ('Predicting Graph Categories from Structural Properties', 2018.0)\n",
      "FAILED: ('Early Estimation Model for 3DÂ–Discrete Indian Sign Language Recognition Using Graph Matching', 2018.0)\n",
      "FAILURE: ('Survey on the Graph Alignment Problem and a Benchmark of Suitable Algorithms', 2013.0)\n",
      "FAILURE: ('Unsupervised Domain Adaptation Using Regularized Hyper-Graph Matching', 2018.0)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(subjects)\n",
    "hashes = subjects.get_to_read_hashes()\n",
    "\n",
    "outfile = \"./ThesisClass/thesis_bibliography.txt\"\n",
    "\n",
    "for p_hash in hashes:\n",
    "    try:\n",
    "        p = db.all_papers[p_hash]\n",
    "        bib = requests.request('GET', 'http://dx.doi.org/' + p.DOI, \n",
    "        headers={'Accept':'application/x-bibtex'}, timeout=100)\n",
    "        if bib.text.find(\"<\") < 0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"FAILURE:\", p_hash)\n",
    "    except KeyError:\n",
    "        print(\"FAILED:\", p_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7640 edges written with max_edges = 1000000.0\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(subjects)\n",
    "subjects.citation_network(db, 'subject_tagged_network.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comparing performance of graph matching algorithms on huge graphs ['Signal Processing', 'Software', 'Artificial Intelligence', 'Computer Vision and Pattern Recognition']\n",
      "\n",
      " Indian sign language recognition using graph matching on 3D motion captured signs ['Media Technology', 'Computer Networks and Communications', 'Hardware and Architecture', 'Software']\n",
      "\n",
      " Accurate genotyping across variant classes and lengths using variant graphs ['Genetics']\n",
      "\n",
      " SSGCI: Subgraph Spotting in Graph Representations of Comic book Images ['Signal Processing', 'Software', 'Artificial Intelligence', 'Computer Vision and Pattern Recognition']\n",
      "\n",
      " Context-Dependent Random Walk Graph Kernels and Tree Pattern Graph Matching Kernels with Applications to Action Recognition ['Software', 'Computer Graphics and Computer-Aided Design']\n",
      "\n",
      " On random graphs I ['Mathematics']\n",
      "\n",
      " Algorithms for Graph Similarity and Subgraph Matching ['Geometry and Topology']\n",
      "\n",
      " An Integer Projected Fixed Point Method for Graph Matching and MAP Inference ['Software', 'Artificial Intelligence', 'Computer Vision and Pattern Recognition']\n",
      "\n",
      " Early Estimation Model for 3D–Discrete Indian Sign Language Recognition Using Graph Matching ['General Computer Science']\n",
      "\n",
      " On a certain distance between isomorphism classes of graphs ['Computer Networks and Communications', 'Hardware and Architecture', 'Software', 'Information Systems']\n",
      "\n",
      " Graph alignment for semi-supervised semantic role labeling ['Linguistics and Language', 'Artificial Intelligence', 'Language and Linguistics', 'Computer Science Applications']\n",
      "11\n",
      "5780\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# SUBJECT IS A USELESS PIECE OF CROSSREF INFO\n",
    "i = 0\n",
    "with_subject = 0\n",
    "without_subject = 0\n",
    "subjects = set()\n",
    "for p_hash, p in db.all_papers.items():\n",
    "    i += 1\n",
    "    if i > 10000:\n",
    "        break\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(p.item['subject'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \"\"\"\n",
    "    if p.subject:\n",
    "        print(\"\\n\",p.title, p.subject)\n",
    "        subjects.update(set(p.subject))\n",
    "        with_subject += 1\n",
    "    else:\n",
    "        without_subject += 1\n",
    "\n",
    "print(with_subject)\n",
    "print(without_subject)\n",
    "print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.349999999999998\n",
      "41.6\n",
      "33.9\n",
      "52.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "family = np.array([0.03,0.06,0.03,0.1,0.1,0.14,0.14,0.4])\n",
    "comb = np.array([0.16,0.08,0.22,0.05,0.08,0.22,0.05,0.14])\n",
    "trail = np.array([0.13,0.05,0.16,0.03,0.22,0.16,0.03,0.22])\n",
    "helicopter = np.array([0.25,0.08,0.25,0.08,0.12,0.09,0.05,0.08])\n",
    "\n",
    "u = np.array([100.0,70,55,50,20,15,10,0])\n",
    "\n",
    "for action in [family, comb, trail, helicopter]:\n",
    "    print(np.dot(u,action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[ 0  4  8 10]\n",
      "\n",
      "[[-2 -1  0]\n",
      " [-2 -1  0]\n",
      " [-2 -1  0]\n",
      " [-2 -1  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(12).reshape(4,3)\n",
    "shifted = A - np.max(A,axis=1).reshape(4,1)\n",
    "indices = np.array([0,1,2,1])\n",
    "print(A)\n",
    "print(np.choose(indices, A.T))\n",
    "print()\n",
    "print(shifted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy ('CD', 'DC') : Payoffs [28.95 31.05]\n",
      "Strategy ('DC', 'CD') : Payoffs [28.95 31.05]\n",
      "Strategy ('CC', 'CC', 'CD') : Payoffs [24.02 35.98]\n",
      "Strategy ('CC', 'CC', 'DC') : Payoffs [24.02 35.98]\n",
      "Strategy ('CD', 'CC', 'DC') : Payoffs [28.6 31.4]\n",
      "Strategy ('CD', 'DC', 'DC') : Payoffs [24.76 35.24]\n",
      "Strategy ('DC', 'CC', 'CD') : Payoffs [28.6 31.4]\n",
      "Strategy ('DC', 'CD', 'CD') : Payoffs [24.76 35.24]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "payoffs = {'CC':(3,3),'CD':(1,5),'DC':(5,1),'DD':(2,2)}\n",
    "beta = 0.9 # discount factor\n",
    "desired_reward = np.array([24.0,31.0])\n",
    "\n",
    "for n in [2,3]:\n",
    "    \n",
    "    scale = 1.0/(1.0-beta**n)\n",
    "\n",
    "    # Explore the 2^n possible strategies for a sequence of length n\n",
    "    for strategy in itertools.product(('CC','CD','DC','DD'), repeat=n):\n",
    "\n",
    "        # Construct the discounted payoffs for the infinite discounted strategy\n",
    "        payoff = np.zeros((2,n))\n",
    "        for i in range(n):\n",
    "            payoff[:,i] = payoffs[strategy[i]]\n",
    "        discount = np.array([beta**i for i in range(n)])\n",
    "        \n",
    "        # This might make the strategy backwards with respect to player 1 vs.\n",
    "        # player 2, but it's simpler and an easy fix.\n",
    "        reward = np.sort(scale*np.dot(payoff, discount))\n",
    "\n",
    "        # Construct the enforceable and \">[24,31]\" constraint\n",
    "        maximin_payoff = 2.0*scale*np.sum(discount)*np.ones(2)\n",
    "        is_enforceable = np.prod((reward >= maximin_payoff))\n",
    "        satisfies_constraint = np.prod((reward >= desired_reward))\n",
    "        \n",
    "        # Report success if applicable\n",
    "        if is_enforceable and satisfies_constraint:\n",
    "            print(\"Strategy\", strategy, \":\", \"Payoffs\", np.round(reward,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
