[0] Weiming Hu, Baoxin Wu, Pei Wang, Chunfeng Yuan, Context-Dependent Random Walk Graph Kernels and Tree Pattern Graph Matching Kernels with Applications to Action Recognition
[1] K.M. Borgwardt, C.S. Ong, S. Schonauer, S. Vishwanathan, A.J. Smola, and H.-P. Kriegel, “Protein function prediction via graph kernels,” Bioinformatics, vol. 21, pp. 47-56, 2005.
[2] E.Z. Borzeshi, M. Piccardi, and R. Xu, “A discriminative prototype selection approach for graph embedding in human action recognition,” in Proc. of IEEE International Conference on Computer Vision, pp. 1295-1301, 2011.
[3] O. Celiktutan, C. Wolf, B. Sankur, and E. Lombardi, “Real-time exact graph matching with application in human action recognition,” in Proc. of International Workshop on Human Behavior Understanding, pp. 17-28, 2012.
[4] P. Dollar, V. Rabaud, G. Cottrell, and S. Belongie, “Behavior recognition via sparse spatio-temporal features,” in Proc. of IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance, pp. 65-72, 2005.
[5] T. Gartner, P. Flach, and S. Wrobel, “On graph kernels: hardness results and efficient alternatives,” Learning Theory and Kernel Machines, vol. 2777 of the series Lecture Notes in Computer Science, pp. 129-143, 2003.
[6] U. Gaur, Y. Zhu, B. Song, and A. Roy-Chowdhury, “A string of feature graphs model for recognition of complex activities in natural videos,” in Proc. of IEEE International Conference on Computer Vision, pp. 2595-2602, 2011.
[7] B. Gauzere, L. Brun, D. Villemin, and M. Brun, “Graph kernels based on relevant patterns and cycle information for chemoinformatics,” in Proc. of IEEE International Conference on Pattern Recognition, pp. 1775-1778, 2012.
[8] Z. Harchaoui and F. Bach, “Image classification with segmentation graph kernels,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2007.
[9] W. Imrich and S. Klavzar, “Product graphs: structure and recognition,” John Wiley & Sons, New York, 2000.
[10] Z. Jiang, Z. Lin, and L.S. Davis, “Recognizing human actions by learning and matching shape-motion prototype trees,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 34, no. 3, pp. 533-547, 2012.
[11] A. Kovashka and K. Grauman, “Learning a hierarchy of discriminative space-time neighborhood features for human action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2046-2053, 2010.
[12] Q.V. Le, W.Y. Zou, S.Y. Yeung, and A.Y. Ng, “Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 3361-3368, 2011.
[13] M. Parsana, S. Bhattacharya, C. Bhattacharya, and K. Ramakrishnan, “Kernels on attributed pointsets with applications,” in Proc. of Annual Conference on Neural Information Processing Systems, pp. 1129-1136, 2007.
[14] K. Raja, I. Laptev, P. Perez, and L. Oisel, “Joint pose estimation and action recognition in image graphs,” in Proc. of IEEE International Conference on Image Processing, pp. 25-28, 2011.
[15] M.D. Rodriguez, J. Ahmed, and M. Shah, “Action MACH: a spatio-temporal maximum average correlation height filter for action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2008.
[16] C. Schuldt, I. Laptev, and B. Caputo, “Recognizing human actions: a local SVM approach,” in Proc. of IEEE International Conference on Pattern Recognition, pp. 32-36, 2004.
[17] P. Scovanner, S. Ali, and M. Shah, “A 3-dimensional sift descriptor and its application to action recognition,” in Proc. of IEEE International Conference on Microwave Magnetics, pp. 357-360, 2007.
[18] A.P. Ta, C. Wolf, G. Lavoue, and A. Baskurt, “Recognizing and localizing individual activities through graph matching,” in Proc. of IEEE International Conference on Advanced Video and Signal Based Surveillance, pp. 196-203, 2010.
[19] M. Varma and B.R. Babu, “More generality in efficient multiple kernel learning,” in Proc. of IEEE International Conference on Machine Learning, pp. 1065-1072, 2009.
[20] S. Vishwanathan, N.N. Schraudolph, R. Kondor, and K.M. Borgwardt, “Graph kernels,” Journal of Machine Learning Research, vol. 11, no. 2, pp. 1201-1242, 2010.
[21] H. Wang, A. Klaser, C. Schmid, and C.-L. Liu, “Action recognition by dense trajectories,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 3169-3176, 2011.
[22] H. Wang, M. M. Ullah, A. Klaser, I. Laptev, and C. Schmid, “Evaluation of local spatio-temporal features for action recognition,” in Proc. of British Machine Vision Conference, pp. 124.1-124.11, Sep. 2009.
[23] L. Wang, Y. Qiao, and X. Tang, “Motionlets: Mid-level 3D parts for human motion recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2674-268, 2013.
[24] L. Yeffet and L. Wolf, “Local trinary patterns for human action recognition,” in Proc. of IEEE International Conference on Computer Vision, pp. 492-497, 2009.
[25] J. Nocdal and S. Wrihgt, “Numerical optimization”, In New York; Sringer Verlag, 2nd ed, 2006.
[26] P. Mahe and J.-P. Vert, “Graph kernels based on tree patterns for molecules,” Machine Learning, vol. 75, no. 1, pp. 3-35, April 2009.
[27] S. Lyu, “Mercer kernels for object recognition with local features,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, vol. 2, pp. 223-229, 2005.
[28] M. Cho, J. Sun, O. Duchenne, and J. Ponce. “Finding matches in a haystack: a max-pooling strategy for graph matching in the presence of outliers,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2091-2098, 2014.
[29] T. Cour, P. Srinivasan, and J. Shi, “Balanced graph matching,” in Proc. of Annual Conference on Neural Information Processing Systems, pp. 313-320, 2006.
[30] A. Egozi, Y. Keller, and G. Hugo, “A probabilistic approach to spectral graph matching,” IEEE Trans. on Patter Analysis and Machine Intelligence, vol. 35, no. 1, pp. 8-27, 2013.
[31] M. Leordeanu and M. Hebert, “A spectral technique for correspondence problem using pairwise constraints,” in Proc. of IEEE International Conference on Computer Vision, pp. 1482-1489, 2005.
[32] I.N. Junejo, E. Dexter, I. Laptev, and P. Perez, “View-independent action recognition from temporal self-similarities,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 33, no. 1, pp. 172-185, 2011.
[33] H. Wang and C. Schmid, “Action recognition with improved trajectories,” in Proc. of IEEE International Conference on Computer Vision, pp. 3551-3558, 2013.
[34] C. Wallraven and B. Caputo, “Recognition with local features: the kernel recipe,” in Proc. of IEEE International Conference on Computer Vision, pp. 257-264, 2003.
[35] H. Wang, C. Yuan, G. Luo, W. Hu, and C. Sun, “Action recognition using linear dynamic systems,” Pattern Recognition, vol. 46, no. 6, pp. 710-1718, 2013.
[36] L. Wang and H. Sahbi, “Directed acyclic graph kernels for action recognition,” in Proc. of IEEE International Conference on Computer Vision, pp. 3168-3175, 2013.
[37] B. Wu, C. Yuan, and W. Hu. “Human action recognition based on context-dependent graph kernels,” in Proc. of IEEE Conference on Computer Vision and Patten Recognition, pp. 2609-2616, 2014.
[38] S. Jones and L. Shao, “A multigraph representation for improved unsupervised/semi-supervised learning of human actions,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 820-826, 2014.
[39] W. Guo and G. Chen, “Human action recognition via multitask learning base on spatial-temporal feature,” Information Sciences, vol. 320, no. 3, pp. 418-428, Nov. 2015.
[40] S. Ma, L. Sigal, and S. Sclaroff, “Space-time tree ensemble for action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 5024-5032, 2015.
[41] H. Zhang, W. Zhou, C. Reardon, and L.E. Parker, “Simplex-based 3D spatio-temporal feature description for action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2067-2074, 2014.
[42] L. Sun, K. Jia, T. Chan, Y. Fang, G. Wang, and S. Yan, “DL-SFA: Deeply-learned slow feature analysis for action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2625-2632, 2014.
[43] V. Veeriah, N. Zhuang, and G. Qi, “Differential recurrent neural networks for action recognition,” in Proc. of IEEE International Conference on Computer Vision, pp. 4041-4049, 2015.
[44] D. Wang, Q. Shao, and X. Li, “A new unsupervised model of action recognition,” in Proc. of IEEE International Conference on Image Processing, pp. 1160-1164, 2015.
[45] Y. Shi, W. Zeng, T. Huang, and Y. Wang, “Learning deep trajectory descriptor for action recognition in videos using deep neural networks,” in Proc. of IEEE International Conference on Multimedia and Expo, pp. 1-6, 2015.
[46] A. Gaidon, Z. Harchaoui, and C. Schmid, “Activity representation with motion hierarchies,” International Journal of Computer Vision, vol. 107, no. 3, pp. 219-238, May 2014.
[47] O. Kihl, D. Picard, and P-H. Gosselin, “A unified framework for local visual descriptors evaluation,” Pattern Recognition, vol. 48, no. 4, pp. 1174-1184, April 2015.
[48] L. Pei, M. Ye, X. Zhao, Y. Dou, and J. Bao, “Action recognition by learning temporal slowness invariant features,” Visual Computer, vol. 32, no. 11, pp. 1395-1404, Nov. 2016.
[49] N.A. Harbi and Y. Gotoh, “A unified spatio-temporal human body region tracking approach to action recognition,” Neurocomputing, vol. 161, no. c, pp. 56-64, August 2015.
[50] K. Schindler and L.V. Gool, “Action snippets: how many frames does human action recognition require?” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2008.
[51] V. Kantorov and I. Laptev, “Efficient feature extraction, encoding and classification for action recognition,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2593-2600, 2014.
[52] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld, “Learning realistic human actions from movies,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, June 2008.
[53] M. Bregonzio, S. Gong, and T. Xiang, “Recognising action as clouds of space-time interest points,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1948-1955, June 2009.
[54] N.B. Aoun, M. Mejdoub, and C.B. Amar, “Graph-based approach for human action recognition using spatio-temporal features,” Journal of Visual Communication and Image Representation, vol. 25, no. 2, pp. 329-338, Feb. 2014.
[55] P. Mahe, N. Ueda, T. Akutsu, J.-L. Perret, and J.-P. Vert, “Extensions of marginalized graph kernels,” in Proc. of International Conference on Machine Learning, pp. 552-559, 2004.
[56] N. Shervashidze, P. Schweitzer, E.J. Leeuwen, K. Mehlhorn, and K.M. Borgwardt. “Weisfeiler-lehman graph kernels,” Journal of Machine Learning Research, vol. 12, pp. 2539-2561, 2011.
[57] N. Shervashidze, S. Vishwanathan, and T.H. Petri, “Efficient graphlet kernels for large graph comparison,” Journal of Machine Learning Research, vol. 5, pp. 488-495, 2009.
[58] Y. Kong, Z. Ding, J. Li, and Y. Fu, “Deeply learned view-invariant features for cross-view action recognition,” IEEE Trans. on Image Processing, vol. 26, no.6, pp. 3028-3037, 2017.
[59] Y. Kong and Y. Fu, “Max-margin heterogeneous information machine for RGB-D action recognition,” International Journal of Computer Vision, vol. 123, no.3, 350-371, 2017.
[60] Q. Li, H. Cheng, Y. Zhou, and G. Huo, “Human action recognition using improved salient dense trajectories,” Computational Intelligence and Neuroscience, vol. 2016, Article ID: 6750459.
[61] A. Alfaro, D. Mery, and A. Soto, “Action recognition in video using sparse coding and relative features,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2688-2697, 2016.